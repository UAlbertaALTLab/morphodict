{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e4dc55b-c0cb-4688-926e-4f398be8a3c7",
   "metadata": {},
   "source": [
    "# Preparing news vectors\n",
    "\n",
    "We want to use [word2vec] pre-computed word vectors to approximate\n",
    "the semantic distance between user queries and dictionary definitions.\n",
    "\n",
    "See Daniel Dacanay, Antti Arppe, and Atticus Harrigan, [Computational Analysis versus Human Intuition: A Critical Comparison of Vector Semantics with Manual Semantic Classification in the Context of Plains Cree][vecpaper1], in \n",
    "Proceedings of the 4th Workshop on the Use of Computational Methods in the Study of Endangered Languages; and \n",
    "Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean, [Efficient Estimation\n",
    "of Word Representations in Vector Space][eewrvs], in Proceedings of Workshop at\n",
    "ICLR, 2013.\n",
    "\n",
    "[eewrvs]: http://arxiv.org/pdf/1301.3781.pdf\n",
    "[word2vec]: https://code.google.com/archive/p/word2vec/\n",
    "[vecpaper1]: https://computel-workshop.org/wp-content/uploads/2021/02/2021.computel-1.5.pdf\n",
    "\n",
    "But first we are going to massage the precomputed vectors into an easier-to-use form.\n",
    "\n",
    "There are a couple of things to do first:\n",
    "  - Use a file format that’s faster to load\n",
    "  - Save time and space by pruning keys we’ll never query for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce4b5c8-91f9-4b5b-b2a4-a4bd77d02cee",
   "metadata": {},
   "source": [
    "## The upstream files\n",
    "\n",
    "First, we’ll store the files in the `res/vector_models` directory.\n",
    "Let’s make a variable that points at that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62db16f5-6d8f-4067-accb-71014069bb60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# jupyter does not expose the filename of the notebook, and\n",
    "# the kernel working directory appears to be the directory\n",
    "# containing the first notebook opened in the jupyter session.\n",
    "def find_project_root(target_filename='Pipfile'):\n",
    "    \"\"\"Walk upwards from current dir, looking for target_filename\"\"\"\n",
    "    start_directory = directory = Path(os.getcwd())\n",
    "    while directory.parent != directory:\n",
    "        if (directory / target_filename).exists():\n",
    "            return directory\n",
    "        directory = directory.parent\n",
    "    else:\n",
    "        raise Exception(f'Could not find {target_filename!r} in any parent of {start_directory}')\n",
    "    return directory\n",
    "\n",
    "ROOT = find_project_root()\n",
    "VECTOR_DIR = ROOT / 'morphodict' / 'resources' / 'vector_models'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd972b61-145b-4718-a252-44ec3e3e20f5",
   "metadata": {},
   "source": [
    "The upstream `GoogleNews-vectors-negative300.bin.gz` file is not checked in here, so you’ll have to get it elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c01ecf3-7245-4af3-b2fa-3bf2a4276fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1,647,046,656\n",
      "1,647,046,656 GoogleNews-vectors-negative300.bin.gz\n"
     ]
    }
   ],
   "source": [
    "!env BLOCK_SIZE=\"'1\" ls -s $VECTOR_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bca1402-7be3-4f6b-b31b-e4815d4a6928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.2 s, sys: 2.82 s, total: 33 s\n",
      "Wall time: 30.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "vectors = VECTOR_DIR / 'GoogleNews-vectors-negative300.bin.gz'\n",
    "\n",
    "wv = KeyedVectors.load_word2vec_format(vectors, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56325644-b420-4672-8821-a7859af2f0e6",
   "metadata": {},
   "source": [
    "It’s called a keyed vector because it maps keys to vectors.\n",
    "\n",
    "If we run some basic stats, we see: there are 3 million, 300-dimensional vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a819e9-9e9f-4fe0-8263-cff2b02ebf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05419922  0.01708984 -0.00527954 ... -0.36523438 -0.13769531\n",
      " -0.12890625]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def shortprint(a):\n",
    "    with np.printoptions(threshold=10):\n",
    "        print(a)\n",
    "shortprint(wv['hello'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd182e22-82df-4601-a57c-dc659694075e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wv['hello'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1b23615-4bd3-4cb6-8c18-af3f630b4e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wv.key_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044006f5-5da5-4e77-8bd7-bbb2686e3963",
   "metadata": {},
   "source": [
    "We can query for similar concepts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89d4060e-09b7-410b-8a38-82c2069ba5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hello', 1.0),\n",
       " ('hi', 0.6548984050750732),\n",
       " ('goodbye', 0.6399056315422058),\n",
       " ('howdy', 0.6310956478118896),\n",
       " ('goodnight', 0.5920578241348267),\n",
       " ('greeting', 0.5855877995491028),\n",
       " ('Hello', 0.5842196345329285),\n",
       " (\"g'day\", 0.5754078030586243),\n",
       " ('See_ya', 0.5688871741294861),\n",
       " ('ya_doin', 0.5643119812011719)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_vector(wv['hello'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895f332a-b8eb-45d3-b483-978fa233f49d",
   "metadata": {},
   "source": [
    "And then the deep magic is that this vector model appears to capture semantic relationships.\n",
    "\n",
    "Take the physics away from Einstein, add painting, and what do you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6c6124e-e332-4238-8e17-d4afdf623e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('painting', 0.6713024973869324),\n",
       " ('Picasso', 0.5790765285491943),\n",
       " ('Rembrandt', 0.5525932312011719),\n",
       " ('Guercino', 0.5175808072090149),\n",
       " ('paintings', 0.5061424970626831),\n",
       " ('Picasso_Monet', 0.5017005205154419),\n",
       " ('Balthus', 0.5001558661460876),\n",
       " ('Cezanne', 0.4969138503074646),\n",
       " ('Warhol', 0.49574798345565796),\n",
       " ('Vincent_Van_Gogh', 0.4956248998641968)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_vector(wv['Einstein'] - wv['physics'] + wv['painting'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcc3d51-1890-4c2d-8674-e45f48d524b0",
   "metadata": {},
   "source": [
    "### Faster file format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894f79d2-54be-44ce-9206-1811f958da04",
   "metadata": {},
   "source": [
    "Let’s use the built-in gensim file format, which saves the vectors into a memory-mapping numpy array on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19d2eef7-326b-4edc-ad12-a1856938070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "REDUCED_FILE = os.fspath(VECTOR_DIR / 'news_vectors.kv')\n",
    "\n",
    "wv.save(REDUCED_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "688ca46b-49e3-4e93-9454-be492a3438b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5,363,204,096\n",
      "1,647,046,656 GoogleNews-vectors-negative300.bin.gz\n",
      "  116,154,368 news_vectors.kv\n",
      "3,600,003,072 news_vectors.kv.vectors.npy\n"
     ]
    }
   ],
   "source": [
    "!env BLOCK_SIZE=\"'1\" ls -s $VECTOR_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a50adb87-71ec-4b88-abf7-196083875cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05419922  0.01708984 -0.00527954 ... -0.36523438 -0.13769531\n",
      " -0.12890625]\n",
      "CPU times: user 2.57 s, sys: 1.12 s, total: 3.69 s\n",
      "Wall time: 1.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('hello', 1.0),\n",
       " ('hi', 0.6548984050750732),\n",
       " ('goodbye', 0.6399056315422058),\n",
       " ('howdy', 0.6310956478118896),\n",
       " ('goodnight', 0.5920578241348267),\n",
       " ('greeting', 0.5855877995491028),\n",
       " ('Hello', 0.5842196345329285),\n",
       " (\"g'day\", 0.5754078030586243),\n",
       " ('See_ya', 0.5688871741294861),\n",
       " ('ya_doin', 0.5643119812011719)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wv = KeyedVectors.load(REDUCED_FILE, mmap='r')\n",
    "with np.printoptions(threshold=10):\n",
    "    print(wv['hello'])\n",
    "wv.similar_by_vector(wv['hello'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4b2a746-02f8-4a30-be63-2a87e2dd8457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.75 s, sys: 440 ms, total: 2.19 s\n",
      "Wall time: 145 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('hello', 1.0),\n",
       " ('hi', 0.6548984050750732),\n",
       " ('goodbye', 0.6399056315422058),\n",
       " ('howdy', 0.6310956478118896),\n",
       " ('goodnight', 0.5920578241348267),\n",
       " ('greeting', 0.5855877995491028),\n",
       " ('Hello', 0.5842196345329285),\n",
       " (\"g'day\", 0.5754078030586243),\n",
       " ('See_ya', 0.5688871741294861),\n",
       " ('ya_doin', 0.5643119812011719)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "wv.similar_by_vector(wv['hello'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7019f6e5-837b-44df-8598-93363da76b52",
   "metadata": {},
   "source": [
    "This file is *much* faster to load, ~1 second instead of 30 seconds, but it is also much larger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b689e97-1457-4a2f-8298-678a6a135853",
   "metadata": {},
   "source": [
    "#### Float precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4e23c7-5d9c-421d-9005-86312b87619c",
   "metadata": {},
   "source": [
    "Interestingly, if we look inside the original file, we only started out with 16-bit floats, but they’re being stored as 32-bit ones. We can halve the file size by setting the data type correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03126af5-ece7-4ff8-88b1-b43984c16b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000  93 be 00 00 14 3e 00 00  31 3e 00 00 41 3d 00 00  |.....>..1>..A=..|\n",
      "00000010  b8 3d 00 00 8f be 00 00  32 be 00 00 16 bf 00 00  |.=......2.......|\n",
      "00000020  08 be 00 00 c9 3e 00 00  9f be 00 00 5e 3c 00 00  |.....>......^<..|\n",
      "00000030  30 be 00 00 58 bc 00 00  57 3e 00 00 8d 3e 00 00  |0...X...W>...>..|\n",
      "00000040  a2 be 00 00 ee bd 00 00  e5 be 00 00 8f bd 00 00  |................|\n",
      "00000050  21 be 00 00 3f be 00 00  74 3e 00 00 05 3f 00 00  |!...?...t>...?..|\n",
      "00000060  2f 3e 00 00 dd bd 00 00  fa 3d 00 00 f6 3e 00 00  |/>.......=...>..|\n",
      "00000070  16 be 00 00 5c 3e 00 00  3c 3e 00 00 2d be 00 00  |....\\>..<>..-...|\n",
      "00000080  9d bd 00 00 5a 3e 00 00  fe 3c 00 00 e6 3e 00 00  |....Z>...<...>..|\n",
      "00000090  24 be 00 00 ec 3e 00 00  59 be 00 00 c9 3d 00 00  |$....>..Y....=..|\n",
      "\n",
      "gzip: 000000a0  f7 bd 00 00 07 bf 00 00  9d 3e 00 00 d8 bc 00 00  |.........>......|\n",
      "stdout: Broken pipe\n",
      "000000b0  e9 3d 00 00 20 ba 00 00  4d 3e 00 00 b6 be 00 00  |.=.. ...M>......|\n",
      "000000c0  ba bc 00 00 a7 bd 00 00  35 3e 00 00 e2 bd 00 00  |........5>......|\n",
      "000000d0  a3 3e 00 00 7b 3e 00 00  5d 3e 00 00 80 3d 00 00  |.>..{>..]>...=..|\n",
      "000000e0  22 be 00 00 0c be 00 00  0e bf 00 00 19 3e 00 00  |\"............>..|\n",
      "000000f0  d2 bd 00 00 32 be 00 00  21 be 00 00 2c 3e 00 00  |....2...!...,>..|\n",
      "00000100\n"
     ]
    }
   ],
   "source": [
    "!zcat $VECTOR_DIR/GoogleNews-vectors-negative300.bin.gz \\\n",
    "    | head -c 300M | tail -c 256 | hexdump -C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9de43a63-2196-4e02-b711-47a105dddfa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.vectors.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5cb521f-faa3-4865-801f-8e485a220192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0542   0.01709 -0.00528 ... -0.3652  -0.1377  -0.1289 ]\n"
     ]
    }
   ],
   "source": [
    "wv2 = KeyedVectors.load(REDUCED_FILE, mmap='r')\n",
    "wv2.vectors = wv2.vectors.astype('float16')\n",
    "shortprint(wv2['hello'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc49aeaa-1645-4c39-ab21-41ad44559786",
   "metadata": {},
   "source": [
    "But, sadly, doing so makes lookups take more than **15x** as long, going from a fraction of a second to multiple seconds. This is because modern CPUs do not generally have built-in 16-bit float operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a04f375f-2ff2-4a43-9839-e2ff379b7d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.79 s, sys: 924 ms, total: 4.71 s\n",
      "Wall time: 2.34 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('hello', 1.0000041723251343),\n",
       " ('hi', 0.6548804640769958),\n",
       " ('goodbye', 0.639906108379364),\n",
       " ('howdy', 0.6311008334159851),\n",
       " ('goodnight', 0.5920441150665283),\n",
       " ('greeting', 0.5855898857116699),\n",
       " ('Hello', 0.5842040777206421),\n",
       " (\"g'day\", 0.5753953456878662),\n",
       " ('See_ya', 0.5688733458518982),\n",
       " ('ya_doin', 0.5643098950386047)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "wv2.similar_by_vector(wv2['hello'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45ed56f0-cd6a-47e6-853e-a3590c37970c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.78 s, sys: 591 ms, total: 2.37 s\n",
      "Wall time: 154 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('hello', 1.0),\n",
       " ('hi', 0.6548984050750732),\n",
       " ('goodbye', 0.6399056315422058),\n",
       " ('howdy', 0.6310956478118896),\n",
       " ('goodnight', 0.5920578241348267),\n",
       " ('greeting', 0.5855877995491028),\n",
       " ('Hello', 0.5842196345329285),\n",
       " (\"g'day\", 0.5754078030586243),\n",
       " ('See_ya', 0.5688871741294861),\n",
       " ('ya_doin', 0.5643119812011719)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "wv.similar_by_vector(wv['hello'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e783d2f-4936-4b83-a8c0-8b333406ee55",
   "metadata": {},
   "source": [
    "If we need to be careful with disk space, we could save the vectors on disk as float16 and then do `.astype('float32')` on load, which would only takes a few seconds. It would use more disk space, but may be much faster than dealing with a compressed file.\n",
    "\n",
    "However, anything that’s not `mmap`ing a file gets risky in terms of memory use. A few gigs of data in memory isn’t a big deal for a server with lots of RAM, but (1) if the data isn’t all ready *before* the webserver forks worker processes, 10 copies of a few gigs of data adds up quickly, and (2) it could substantially increase the requirements for developer machines, which might not have many gigabytes of spare RAM.\n",
    "\n",
    "So for now I think we’ll stick with the bigger file that can be processed more efficiently both in terms of RAM and CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ec368e-5212-49e1-a18b-f1ab0e249876",
   "metadata": {},
   "source": [
    "## Pruning keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be54692-e5ca-4e1e-9076-84a75a131600",
   "metadata": {},
   "source": [
    "### Keys with punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7310f79b-d00b-4d4f-a3ff-d9365ea3df3a",
   "metadata": {},
   "source": [
    "The file is still quite large. There’s probably a *lot* of stuff in there we will never, ever query for.\n",
    "\n",
    "For example, what’s the millionth entry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76b46071-69c6-41f7-a89c-db019b19b02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Starwood_Hotels_HOT'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.index_to_key[1_000_000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89c7f80-6509-4c1a-beba-e8ce04b28565",
   "metadata": {},
   "source": [
    "That’s not something we’ll ever query the dictionary for.\n",
    "\n",
    "What are the top keys?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d832e6f-19b7-4648-9d71-03c08686bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(wv.key_to_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c365b98d-10d6-4878-b9c6-b2f3ddce8182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>, in, for, that, is, on, ##, The, with, said, was, the, at, not, as, it, be, from, by, are, I, have, he, will, has, ####, his, an, this, or, their, who, they, but, $, had, year, were, we, more, ###, up, been, you, its, one, about, would, which, out, can, It, all, also, two, after, first, He, do, time, than, when, We, over, last, new, other, her, people, into, In, our, there, A, she, could, just, years, some, U.S., three, million, them, what, But, so, no, like, if, only, percent, get, did, him, game, back, because, now, #.#, before'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\", \".join(keys[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3888786-5e15-4f1a-90b3-ed2aa8f4ecbc",
   "metadata": {},
   "source": [
    "Right away we see that `#`—presumably a placeholder for a number—and `$` are common terms. What keys containing punctuation can we drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f5481ba-cc5a-4aef-a5a7-bb02c49eb769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_', '2,881,208'),\n",
       " ('#', '261,534'),\n",
       " ('-', '202,358'),\n",
       " ('.', '187,835'),\n",
       " ('=', '29,938'),\n",
       " ('/', '24,442'),\n",
       " (\"'\", '17,088'),\n",
       " ('@', '10,956'),\n",
       " (':', '9,749'),\n",
       " ('é', '6,339'),\n",
       " (',', '5,517'),\n",
       " ('®', '4,268'),\n",
       " ('+', '2,530'),\n",
       " ('&', '2,493'),\n",
       " ('*', '2,350'),\n",
       " ('™', '2,206'),\n",
       " ('â', '1,647'),\n",
       " ('á', '1,483'),\n",
       " ('•', '1,428'),\n",
       " ('€', '1,324'),\n",
       " ('ó', '1,181'),\n",
       " ('í', '1,143'),\n",
       " ('ü', '1,125'),\n",
       " ('ñ', '1,045'),\n",
       " ('ö', '993'),\n",
       " ('è', '780'),\n",
       " ('ä', '599'),\n",
       " ('ç', '507'),\n",
       " ('е', '480'),\n",
       " ('ο', '464')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "[(char, f\"{count:,}\")\n",
    "     for (char, count) in Counter(''.join(keys)).most_common()\n",
    "     if char not in string.ascii_letters + string.digits][:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51132db-9590-4585-b5ea-8ae58a1ce2eb",
   "metadata": {},
   "source": [
    "We also see some duplication in terms of case; both “it” and “It” appear as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4afa764d-ce49-4b95-9f24-65b85145c1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('That', 0.8260787129402161),\n",
       " ('This', 0.8164012432098389),\n",
       " (\"It'sa\", 0.7155401706695557),\n",
       " ('But', 0.6960429549217224),\n",
       " ('Of_course', 0.6675450801849365),\n",
       " ('And', 0.6665104031562805),\n",
       " ('Certainly', 0.650726854801178),\n",
       " (\"That'sa\", 0.6421756148338318),\n",
       " ('Obviously', 0.6368812918663025),\n",
       " ('Actually', 0.6258060336112976)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_key('It')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "416a6242-f4ee-4fe8-b0e8-2b669e3b1a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('that', 0.6775559782981873),\n",
       " ('something', 0.6162784695625305),\n",
       " ('just', 0.6107823848724365),\n",
       " ('actually', 0.5887327790260315),\n",
       " ('It', 0.5808414220809937),\n",
       " ('what', 0.5651708245277405),\n",
       " ('anyway', 0.5644350647926331),\n",
       " ('really', 0.5597794055938721),\n",
       " ('so', 0.5579650402069092),\n",
       " ('if', 0.5520145297050476)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_key('it')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8918609a-c4d0-4520-9701-aae0b881cf53",
   "metadata": {},
   "source": [
    "The distinction would definitely be useful for some purposes, but our dictionary lowercases all queries on input, so that would be lost on us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e8b6f33-c19d-4439-81ee-588065848308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "re_double_underscore = re.compile('.*_.*_.*')\n",
    "\n",
    "def figure_out_items_to_keep():\n",
    "    # new_key, vector\n",
    "    to_keep = {}\n",
    "    \n",
    "    # The original data does not seem to include frequencies, but we\n",
    "    # assume that the keys are in frequency order, so we will see\n",
    "    # the most common term first.\n",
    "    for key in keys:        \n",
    "        \n",
    "        pruned_key = key.lower()\n",
    "        if pruned_key in to_keep:\n",
    "            continue\n",
    "        \n",
    "        # drop keys with unwanted punctuation\n",
    "        if any(c in key for c in \"$#.=/'@:,®+&*™•\"):\n",
    "            continue\n",
    "        \n",
    "        has_uppercase_char = key != key.lower()\n",
    "        if has_uppercase_char:\n",
    "            if '_' in key:\n",
    "                continue\n",
    "        \n",
    "        # Skip items like “Dow_Jones_industrial”\n",
    "        if re_double_underscore.match(key):\n",
    "            continue\n",
    "        \n",
    "        to_keep[pruned_key] = wv[key]\n",
    "    return to_keep\n",
    "\n",
    "items_to_keep = figure_out_items_to_keep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "853a26e9-1355-406a-a5bd-3fa21e3bddd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "930045"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(items_to_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06796220-ab3b-477b-9bde-2493dcef4be6",
   "metadata": {},
   "source": [
    "### Taking a top-$n$ subset\n",
    "\n",
    "That’s still a lot of keys, and the ones toward the end don’t seem very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e59a1817-dbbb-427e-a00f-ae9984305f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6f71184-ce2b-4116-95f8-296a277974ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clscs', '2ab', 'imprecation', 'collectivities', 'ezeani', 'barakah', 'amarteifio', 'glennys', 'ingbretson', 'chaotic_jumble']\n"
     ]
    }
   ],
   "source": [
    "offset, n = 500_000, 10; print(list(islice(items_to_keep.keys(), offset, offset + n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f565dd95-4c1d-4074-9229-c95f7f93f2fc",
   "metadata": {},
   "source": [
    "At 100,000 keys in, we still seem to have some more common terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "713b274d-d926-44e3-a5fa-989fce5a449e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bronze_sculptures', 'expandable_memory', 'backyard_barbecue', 'matchmakers', 'volkswagens', 'unconverted', 'abilify', 'grovel', 'cannibalistic', 'intimations']\n"
     ]
    }
   ],
   "source": [
    "offset, n = 100_000, 10; print(list(islice(items_to_keep.keys(), offset, offset + n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e94b0cf-c693-4ee8-9f40-c19e8a4169fc",
   "metadata": {},
   "source": [
    "And 250k isn’t too bad either"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d5e1b00-1ffc-4f17-8ea6-38458f64b384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['louisvillians', 'subjunctive', 'ntgr', 'popenoe', 'mungall', 'panhandles', 'boccio', 'synqor', 'endangered_tigers', 'incentivises']\n"
     ]
    }
   ],
   "source": [
    "offset, n = 250_000, 10; print(list(islice(items_to_keep.keys(), offset, offset + n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aad0e12-05c7-4482-ac90-72dab8cec194",
   "metadata": {},
   "source": [
    "But, subjectively, the bits at 300k don’t seem too useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ecca2eb-341e-45de-b64d-85ec35568c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1l_behind', 'predeployment', 'tuesay', 'refractory_ores', 'gifting_suites', 'skahill', 'sunnites', 'cfml', 'esophageal_cancers', 'arlow']\n"
     ]
    }
   ],
   "source": [
    "offset, n = 300_000, 10; print(list(islice(items_to_keep.keys(), offset, offset + n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e9e3d7-d877-4e6f-87c1-c3d92cd3f9c1",
   "metadata": {},
   "source": [
    "It’s a pretty arbitrary cut-off, but let’s just take the top 300,000 keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f8d6c5e-b895-4b57-b43f-cddb200dd1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 300_000\n",
    "new_wv = KeyedVectors(vector_size=wv.vector_size)\n",
    "new_keys = list(items_to_keep.keys())[:threshold]\n",
    "new_values = list(items_to_keep.values())[:threshold]\n",
    "new_wv.add_vectors(new_keys, new_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f93c5e-39ac-48ec-b7f0-45f84d83e4de",
   "metadata": {},
   "source": [
    "## The pruned file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64a6d87-bc34-4935-890e-58793b27db66",
   "metadata": {},
   "source": [
    "A quick check that things look ok:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7572e8b4-9d1c-4cfc-9144-8cbdab08eecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hi', 0.6188791394233704),\n",
       " ('hiya', 0.5998829007148743),\n",
       " ('hey', 0.5955355167388916),\n",
       " ('oh', 0.5387828350067139),\n",
       " ('dear', 0.5133785605430603),\n",
       " ('oooh', 0.5129778981208801),\n",
       " ('hooray', 0.509107768535614),\n",
       " ('wassup', 0.4983426332473755),\n",
       " ('ooh', 0.49617260694503784),\n",
       " ('whatcha', 0.4949532151222229)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_wv.similar_by_key('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f855867-d8ae-4099-b14a-6100577355ee",
   "metadata": {},
   "source": [
    "Well, that’s disappointingly different—and lower quality—compared to the uppercase version, but it’s actually a fairly uncommon word in news articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8031287-e51d-49b2-8c71-ac11b5646135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20397"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.key_to_index['hello']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0771b39f-9a62-4283-a1d1-83426436b9e9",
   "metadata": {},
   "source": [
    "What about a more common word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b7d7716-c269-48ed-b0e5-8eb1171cdd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2035"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.key_to_index['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a01943b-2a0e-476a-be99-0baaa1a869d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trains', 0.8081232309341431),\n",
       " ('commuter_train', 0.6523401737213135),\n",
       " ('locomotive', 0.6395583152770996),\n",
       " ('freight_train', 0.6207071542739868),\n",
       " ('railway', 0.6071822047233582),\n",
       " ('bus', 0.6067739725112915),\n",
       " ('rail', 0.5885170102119446),\n",
       " ('commuter_trains', 0.5821391344070435),\n",
       " ('tram', 0.5750932097434998),\n",
       " ('carriages', 0.5699437260627747)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_wv.similar_by_key('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8494df8e-48b6-40b4-bd8a-c19621f82888",
   "metadata": {},
   "source": [
    "That seems just fine. Let’s try it for now and revisit it if we run into issues with query quality from not having/trying the uppercase versions, or speed issues from having too many keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d531d553-5c25-4098-b44e-0a1aa56fbc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wv.save(REDUCED_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c2e034e-0a91-41ef-9f0c-c97d2451cf85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2,014,588,928\n",
      "1,647,046,656 GoogleNews-vectors-negative300.bin.gz\n",
      "    7,540,736 news_vectors.kv\n",
      "  360,001,536 news_vectors.kv.vectors.npy\n"
     ]
    }
   ],
   "source": [
    "!env BLOCK_SIZE=\"'1\" ls -s $VECTOR_DIR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
