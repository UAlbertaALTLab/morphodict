{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f7b4158-7f71-437d-aec3-7040f2264466",
   "metadata": {},
   "source": [
    "# Search feature weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ba11cc-7ce3-499c-9e1b-8ddfcf9b8308",
   "metadata": {},
   "source": [
    "This notebook computes feature weights for a search ranking model.\n",
    "\n",
    "As of early 2020, search ranking was being done by an ad-hoc pairwise comparison function that may not even be transitive. We want to replace it with a more structured and analyzable approach that can additional search features besides corpus frequency, such as cosine vector distance for now, with room for more features later.\n",
    "\n",
    "The basic pieces are:\n",
    "  - Use occurrence of a search result in the search survey as a 0-or-1 relevance variable\n",
    "  - Create a relevance score from that using some fairly basic linear modelling techniques to compute best-fit feature weights\n",
    "  - Measure success by the three10 score: the mean percentage of how many top-3 results from the linguist survey appear in the top 10 search results\n",
    "\n",
    "There are many interesting possible future improvements here, such as:\n",
    "  - Use occurence anywhere in sample, instead of top3 results only, for training\n",
    "  - More precise training data, e.g., relevance rankings of 1-5\n",
    "  - Handle homonyms in training data instead of matching purely on wordform text\n",
    "  - More training data, specifically how many results per query we have human scores for\n",
    "  - More features, e.g., tf-idf\n",
    "  - Higher quality features, e.g., better stopword filtering in vector computations\n",
    "  - Map features to have similar ranges and distributions to better allow the regression to more effectively compare them\n",
    "  - Separate training and test sets\n",
    "  - Fancier models\n",
    "  - Better evaluation functions, such as discounted cumulative gain\n",
    "\n",
    "That said, having all the pieces together, even in a very basic form, is already an improvement over the existing search, so let’s start with that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead8a046-bee2-4c92-8ffc-c18252766934",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00ff282-5533-4968-8ecd-0003007fa204",
   "metadata": {},
   "source": [
    "Load some libraries. `weighting_nb_code.py` contains some more python-y code that was extracted from some exploratory jupyter notebooks once it was working ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c81f34ef-8fb2-44e2-a440-b8eacccdb12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jolenepoulin/.local/share/virtualenvs/morphodict-5QYDyuRz/lib/python3.9/site-packages/statsmodels/compat/pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import weighting_nb_code\n",
    "\n",
    "# Reload the code in `weighting_nb_code.py` by re-running this cell, or\n",
    "# by copying the next line into other cells. If this reload mechanism\n",
    "# proves insufficient, there is also `IPython.lib.deepreload`.\n",
    "importlib.reload(weighting_nb_code);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac649b28-d136-4e38-a6c0-6c0382079b8e",
   "metadata": {},
   "source": [
    "First, if the JSON output file doesn’t already exist, we’ll run the `featuredump` management command to get our raw data. CVD search is not yet on by default, so we add a fancy query to enable it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0362e136-c65b-4e0e-8187-b56f7bec9fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 548/548 [00:57<00:00,  9.48it/s]\n"
     ]
    }
   ],
   "source": [
    "![ -f sample-features.json ] || \\\n",
    "    {weighting_nb_code.BASE_DIR.parent.parent}/crkeng-manage featuredump \\\n",
    "        --prefix-queries-with 'cvd:retrieval' \\\n",
    "        > sample-features.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8b3147-09b9-43dc-a9b1-cf9b8a215333",
   "metadata": {},
   "source": [
    "The loaded feature data looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34c5b3dc-9767-4079-bf20-56e3d567959d",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 2 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mweighting_nb_code\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataframe_from_featuredump\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msample-features.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m data\n",
      "File \u001b[0;32m~/Documents/morphodict/src/CreeDictionary/search_quality/weighting_nb_code.py:20\u001b[0m, in \u001b[0;36mdataframe_from_featuredump\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[0;32m---> 20\u001b[0m         rows\u001b[38;5;241m.\u001b[39mappend(\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     22\u001b[0m all_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mlist\u001b[39m(k \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m row\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[1;32m     23\u001b[0m data \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 2 (char 1)"
     ]
    }
   ],
   "source": [
    "data = weighting_nb_code.dataframe_from_featuredump('sample-features.json')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f046d83b-9ccb-4f5b-9040-0298b2f4beee",
   "metadata": {},
   "source": [
    "Here’s the current combined result survey sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6da056e6-a05e-4947-9888-5a310d2cc547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Nêhiyawêwin 1</th>\n",
       "      <th>Nêhiyawêwin 2</th>\n",
       "      <th>Nêhiyawêwin 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>about</td>\n",
       "      <td>wayês</td>\n",
       "      <td>ohci</td>\n",
       "      <td>papâ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all</td>\n",
       "      <td>kahkiyaw</td>\n",
       "      <td>kapê</td>\n",
       "      <td>mâwaci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>also</td>\n",
       "      <td>mîna</td>\n",
       "      <td>êkwa</td>\n",
       "      <td>kisik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>êkwa</td>\n",
       "      <td>mîna</td>\n",
       "      <td>kisik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>as</td>\n",
       "      <td>kisik</td>\n",
       "      <td>wiya</td>\n",
       "      <td>tâpiskôt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>she sees him</td>\n",
       "      <td>wâpamêw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>starblanket</td>\n",
       "      <td>atâhkakohp</td>\n",
       "      <td>acâhkosa kâ-otakohpit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>star blanket</td>\n",
       "      <td>atâhkakohp</td>\n",
       "      <td>acâhkosa kâ-otakohpit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>being taught</td>\n",
       "      <td>kiskinwahamâkosiw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>they see us</td>\n",
       "      <td>niwâpamikonânak</td>\n",
       "      <td>kiwâpamikonawak</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Query      Nêhiyawêwin 1          Nêhiyawêwin 2 Nêhiyawêwin 3\n",
       "0           about              wayês                   ohci          papâ\n",
       "1             all           kahkiyaw                   kapê        mâwaci\n",
       "2            also               mîna                   êkwa         kisik\n",
       "3             and               êkwa                   mîna         kisik\n",
       "4              as              kisik                   wiya      tâpiskôt\n",
       "..            ...                ...                    ...           ...\n",
       "543  she sees him            wâpamêw                    NaN           NaN\n",
       "544   starblanket         atâhkakohp  acâhkosa kâ-otakohpit           NaN\n",
       "545  star blanket         atâhkakohp  acâhkosa kâ-otakohpit           NaN\n",
       "546  being taught  kiskinwahamâkosiw                    NaN           NaN\n",
       "547   they see us    niwâpamikonânak        kiwâpamikonawak           NaN\n",
       "\n",
       "[548 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighting_nb_code.survey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1b01da-bbcc-40d5-9aa8-4657ff111eb1",
   "metadata": {},
   "source": [
    "And `weighting_nb_code.py` contains a function to annotate the `featuredump` results with the top3/three10 metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f315d186-4c07-465f-bb61-3a23466ebe65",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m weighting_nb_code\u001b[38;5;241m.\u001b[39mtop3_and_310_stats(\u001b[43mdata\u001b[49m, rank_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwebapp_sort_rank\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\n\u001b[1;32m      2\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwordform_text\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefinitions\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual_result_ranks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthree10\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "weighting_nb_code.top3_and_310_stats(data, rank_column=\"webapp_sort_rank\")[\n",
    "    [\"query\", \"wordform_text\", \"definitions\", \"actual_result_ranks\", \"top3\", \"three10\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90553103-1a22-46d8-b9cd-b4096e8af57b",
   "metadata": {},
   "source": [
    "## Initial results from dictionary code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24b018a-2173-4753-9504-9b0db7765729",
   "metadata": {},
   "source": [
    "Without any cosine-vector stuff, here are the current search stats we want to beat. 81.3% for top3, and 59.4% for three10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f724d26-8e7b-4140-9bed-88191b04577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.isfile('sample-features-orig.json'):\n",
    "    data_orig = weighting_nb_code.dataframe_from_featuredump('sample-features-orig.json')\n",
    "    display(weighting_nb_code.top3_and_310_stats_summary(data_orig, rank_column=\"webapp_sort_rank\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dea0de-068d-468d-824b-a9a4540415e1",
   "metadata": {},
   "source": [
    "Note: this won’t exactly match what the django `/search-quality` pages report, because of some differences in determining exactly what the rank is. In the django code, if the results are `(non-lemma1, non-lemma2)`, we count the ranks as `(1, 3)` because the UI display of `non-lemma1` includes its lemma definition at rank 2. Here we skip that for now, but the results should be close enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf51f8d-e6b0-4fec-9972-71a576d130ed",
   "metadata": {},
   "source": [
    "And, for comparison, here are the stats when we added a very basic cosine vector distance model to the search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a935ac0-42a1-48f1-86bd-60197051be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighting_nb_code.top3_and_310_stats_summary(data, rank_column=\"webapp_sort_rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37310af-0026-4ee8-aa47-54399847e462",
   "metadata": {},
   "source": [
    "The top3 score—what percent of desired search results we see anywhere in the list—has gone up. That is, the vector model’s ability to resolve synonyms has improved recall. But the three10 score—what percent of desired search results are near the top—has gone down since we don’t have a good ranking mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ca032-5a63-4119-80c6-4df213e5502c",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344d5741-5c90-478c-94ad-b44d9b6f2769",
   "metadata": {},
   "source": [
    "At this point we have all the definition and feature data from the webapp loaded, and we could experiment by adding more data columns with additional features. Those features could be computed by Python code here, or loaded from data files.\n",
    "\n",
    "For this first version, let’s stick with what we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79163d03-600a-47a7-a264-dfa40d2b15e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_results_for_regression(df):\n",
    "    # The default value used for `fillna()` doesn’t matter if we\n",
    "    # also have an indicator variable, but things get trickier\n",
    "    # with logarithms.\n",
    "    return df.assign(\n",
    "        morpheme_ranking=df[\"morpheme_ranking\"].fillna(1),\n",
    "        has_morpheme_ranking=weighting_nb_code.has_col_as_int(df, \"morpheme_ranking\"),\n",
    "        has_cosine_vector_distance=weighting_nb_code.has_col_as_int(df, \"cosine_vector_distance\"),\n",
    "        cosine_vector_distance=df[\"cosine_vector_distance\"].fillna(1.1),\n",
    "        is_in_survey=df.apply(weighting_nb_code.is_in_survey, axis=1),\n",
    "        keyword_match_len=df['target_language_keyword_match'].apply(len),\n",
    "        pos_match=df[\"pos_match\"].fillna(0),\n",
    "        word_list_freq=df[\"word_list_freq\"].fillna(0),\n",
    "        lemma_freq=df[\"lemma_freq\"].fillna(0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccece31-cea8-4ac7-ae03-8fdb6c8fad13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = prep_results_for_regression(data)\n",
    "results = smf.ols(\n",
    "    \"\"\"\n",
    "    is_in_survey ~\n",
    "        wordform_length\n",
    "        + has_morpheme_ranking\n",
    "        + morpheme_ranking\n",
    "        + pos_match\n",
    "        + word_list_freq\n",
    "        + lemma_freq\n",
    "        + np.log(1 + cosine_vector_distance)\n",
    "    \"\"\",\n",
    "    data=df,\n",
    ").fit()\n",
    "display(results.summary())\n",
    "sorted_results = weighting_nb_code.rank_by_predictor(df, results)\n",
    "weighting_nb_code.top3_and_310_stats_summary(sorted_results, rank_column=\"result_rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cfaabb-483f-4b69-ad95-362e4c84b934",
   "metadata": {},
   "source": [
    "Objectively, we have increased how many of the top survey results we display at all from 81.3% to 83.4%, and we have increased the mean number of them that appear in the top 10 results per query from ~60% to ~70%. That’s great!\n",
    "\n",
    "Let’s take a look at a sample query. Before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac85ec-d7ea-4f45-b769-5efb72c0d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(weighting_nb_code.top3_and_310_stats(data, rank_column='webapp_sort_rank')\n",
    "     .query('query == \"counts\"'))[['query', 'actual_result_ranks', 'top3', 'three10']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b7f4f5-cb8e-42d7-9d84-459273e5bc9f",
   "metadata": {},
   "source": [
    "When searching for ‘counts,’ before all the good results were showing up somewhere in the results, but none of them were in the top 10.\n",
    "\n",
    "Now, with this new ranking model, the top results from the survey show up at the top of the search results, and even in 1, 2, 3 order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08769edd-cf9a-40b8-bf73-f08a5b8e4c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "(weighting_nb_code.top3_and_310_stats(sorted_results, rank_column='result_rank')\n",
    "     .query('query == \"counts\"'))[['query', 'actual_result_ranks', 'top3', 'three10']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd0118a-86b3-4513-a3b6-4eeb11f8daa3",
   "metadata": {},
   "source": [
    "If we look in more detail at the results, we can see that the cosine vector distance and the morpheme ranking are being combined, but one doesn’t overrule the other. Rarer words generally appear later in the list, but a strong CVD score can move it earlier, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b6e160-3ee6-4dab-a9c7-5b2360568805",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results.query(\"query == 'counts'\").sort_values('score', ascending=False)[\n",
    "    ['wordform_text', 'definitions', 'morpheme_ranking',\n",
    "     'has_cosine_vector_distance',\n",
    "     'cosine_vector_distance', 'is_in_survey', 'score']\n",
    " ].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87509745-9f41-499a-aad9-20bd80837fc5",
   "metadata": {},
   "source": [
    "This is quite a bit better than only using the morpheme ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480b528b-16e8-4937-9e04-db2d0ef2731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('sample-features-orig.json'):\n",
    "    display((data_orig.assign(is_in_survey=data_orig.apply(weighting_nb_code.is_in_survey, axis=1))\n",
    "     .query(\"query == 'counts'\").sort_values('webapp_sort_rank')[\n",
    "        ['wordform_text', 'definitions', 'morpheme_ranking', 'is_in_survey']\n",
    "     ]).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f750a-d582-45c0-96b3-7f5aa1752bee",
   "metadata": {},
   "source": [
    "## Model export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf4da87-e037-412a-a619-b6f6e39ce38a",
   "metadata": {},
   "source": [
    "While the model generated by the `statsmodels` library is `pickle`able, since it’s a fairly basic linear model, for now we will just print the parameters to use in the webapp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194f814c-9bc3-4f86-8e15-c499fd51325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.params.to_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919d6dc8-e0d0-433a-b0ea-de12121bcd90",
   "metadata": {},
   "source": [
    "And here are some test vectors for ensuring the implementation is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3b77ce-1e4a-45ec-bdae-740e68003b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def print_test_vector(**kwargs):\n",
    "    df = prep_results_for_regression(pd.DataFrame([{\n",
    "        \"query\": \"counts\",\n",
    "        \"wordform_text\": \"\",\n",
    "        \"target_language_keyword_match\": [],\n",
    "        \"wordform_length\": 0,\n",
    "        \"keyword_match_len\": 0,\n",
    "        \"morpheme_ranking\": np.nan,\n",
    "        \"cosine_vector_distance\": np.nan,\n",
    "        \"pos_match\": 0,\n",
    "        \"corp_freq\": 0,\n",
    "        **kwargs\n",
    "    }]))\n",
    "    ret = results.predict(df)[0]\n",
    "    # future python feature “underscore as a decimal separator”\n",
    "    # https://bugs.python.org/issue43624 would be handy here\n",
    "    ret = f'{ret:_f}'\n",
    "    if '.' in ret:\n",
    "        l, r = ret.split('.')\n",
    "        r = re.sub(r'(...)(?=.)', r'\\1_', r)\n",
    "        ret = f'{l}.{r}'\n",
    "    print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc213dba-903e-4935-8d5c-a7cd997e5c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_test_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b315a0e7-cd4a-4d5d-b02b-45cbc7f45c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_test_vector(cosine_vector_distance=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df56d93-7f75-453d-a20c-cd76638431f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_test_vector(morpheme_ranking=12.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122e7a55-2d13-4007-a1d2-75f69860c0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_test_vector(cosine_vector_distance=0.7, morpheme_ranking=12.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be260dc9-63d9-4f9e-b605-05248a826952",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_test_vector(cosine_vector_distance=0.7, morpheme_ranking=12.8, wordform_length=9, target_language_keyword_match_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66533f5-f59e-44d0-8582-67620757bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_test_vector(cosine_vector_distance=0.7, morpheme_ranking=12.8, pos_match=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7b15ef-22f2-4d91-8454-efd4dc5ba986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
